{"cells": [{"metadata": {}, "cell_type": "code", "source": "#!pip install -U tensorflow\n#!pip install -U keras\n\nimport tensorflow as tf\nimport keras\nfrom keras.models import load_model\nimport numpy as np\nimport h5py\nimport os\nimport pandas as pd\nfrom pandas import DataFrame as df\n\nfrom ibm_botocore.client import Config\nimport ibm_boto3\nfrom IPython.display import HTML\nfrom keras.models import model_from_json\n\nimport sys\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Using TensorFlow backend.\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "markdown", "source": "# Preparing The Data\nIn the below cells, we load the data from IBM Cloud into our working notebook directory.\nWe also demonstrate IBM Watson Studio's integration with .csv files and how they can load into a pandas DataFrame seamlessly."}, {"metadata": {}, "cell_type": "code", "source": "def download_file_cos(credentials,local_file_name,key): \n    '''\n    Wrapper function to download a file from cloud object storage using the\n    credential dict provided and loading it into memory\n    '''\n    cos = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id=credentials['IBM_API_KEY_ID'],\n    ibm_service_instance_id=credentials['IAM_SERVICE_ID'],\n    ibm_auth_endpoint=credentials['IBM_AUTH_ENDPOINT'],\n    config=Config(signature_version='oauth'),\n    endpoint_url=credentials['ENDPOINT'])\n    try:\n        res=cos.download_file(Bucket=credentials['BUCKET'],Key=key,Filename=local_file_name)\n    except Exception as e:\n        print(Exception, e)\n    else:\n        print('File Downloaded')\n        ", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#For this cell, First click on this cell and make sure it is highlighted.\n# Then click on the data icon (the 1s and 0s) on the right side of the screen\n#and navigate to eval.h5 and click on \"Insert to code\" and \"Insert Credentials\" \n#It should produce a code snippet similar to this:\n\n# @hidden_cell\n# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n# You might want to remove those credentials before you share your notebook.\ncredentials_eval = {\n    'IAM_SERVICE_ID': 'xxxx',\n    'IBM_API_KEY_ID': 'xxxx',\n    'ENDPOINT': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n    'IBM_AUTH_ENDPOINT': 'https://iam.ng.bluemix.net/oidc/token',\n    'BUCKET': 'xxxx',\n    'FILE': 'eval.h5'\n}\n\n# Note: the xxxx here is to indicate that that info will be populated based on your access token keys by Watson Studio\n# Make sure you name the dictionary `credentials_eval`", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#For this cell, First click on this cell and make sure it is highlighted.\n# Then click on the data icon (the 1s and 0s) on the right side of the screen\n#and navigate to classifier_model.h5 or model_final.h5 and click on \"Insert to code\" and \"Insert Credentials\" \n#It should produce a code snippet similar to this:\n\n# @hidden_cell\n# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n# You might want to remove those credentials before you share your notebook.\ncredentials_model = {\n    'IAM_SERVICE_ID': 'xxxx',\n    'IBM_API_KEY_ID': 'xxxx',\n    'ENDPOINT': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n    'IBM_AUTH_ENDPOINT': 'https://iam.ng.bluemix.net/oidc/token',\n    'BUCKET': 'xxxx',\n    'FILE': 'classifier_model.h5' #(or alternately `model_final.h5`)\n}\n\n# Note: the xxxx here is to indicate that that info will be populated based on your access token keys by Watson Studio\n# Make sure you name the dictionary `credentials_model`", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Downloading the files from IBM Cloud to the current directory\n#Downloading the model weights as `final_weights.h5` regardless of original name.\ndownload_file_cos(credentials_model,'final_weights.h5','classifier_model.h5')\ndownload_file_cos(credentials_eval,'eval.h5','eval.h5')", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "File Downloaded\nFile Downloaded\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#Repeating the above steps, we will not load the csv files into Pandas DataFrame object directly.\n#Navigate to the class_labels_indices.csv file on the right and click on \"Insert to code\" -> \"Insert pandas dataframe\"\n#It should produce a code snippet similar to below.\n\nimport types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_b814de19900a4db5acdb554945aa9517 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='xxxxx',\n    ibm_auth_endpoint=\"https://iam.ng.bluemix.net/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n\nbody = client_b814de19900a4db5acdb554945aa9517.get_object(Bucket='audiosetclassification-donotdelete-pr-65xlshluvaajgp',Key='class_label_indices.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf_data_1 = pd.read_csv(body)\ndf_data_1.head()\n\n#Note: the \"xxxx\" would be replaced with your API key when you click on \"Insert to code\" -> \"Insert pandas dataframe\".\n\n#Once inserted, delete / comment out the above demo code. \n", "execution_count": 6, "outputs": [{"output_type": "execute_result", "execution_count": 6, "data": {"text/plain": "   index        mid                   display_name\n0      0   /m/09x0r                         Speech\n1      1  /m/05zppz      Male speech, man speaking\n2      2   /m/02zsn  Female speech, woman speaking\n3      3   /m/0ytgt     Child speech, kid speaking\n4      4  /m/01h8n0                   Conversation", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>mid</th>\n      <th>display_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>/m/09x0r</td>\n      <td>Speech</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>/m/05zppz</td>\n      <td>Male speech, man speaking</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>/m/02zsn</td>\n      <td>Female speech, woman speaking</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>/m/0ytgt</td>\n      <td>Child speech, kid speaking</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>/m/01h8n0</td>\n      <td>Conversation</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#Repeat the same for \"eval_segments.csv\" file\n\nbody = client_b814de19900a4db5acdb554945aa9517.get_object(Bucket='audiosetclassification-donotdelete-pr-65xlshluvaajgp',Key='eval_segments.csv')['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\n    \n# This time we have some pre-processing steps as we do not want to import all columns and rows\n# Make sure you pass the following arguments with `pd.read_csv()`\ndf_data_2 = pd.read_csv(body, header=None, names=['video_id', 'start_time', 'end_time'], skiprows=3, usecols=[0,1,2]) #'# YTID', ' start_seconds', ' end_seconds'])\ndf_data_2.head()", "execution_count": 7, "outputs": [{"output_type": "execute_result", "execution_count": 7, "data": {"text/plain": "      video_id  start_time  end_time\n0  --4gqARaEJE         0.0      10.0\n1  --BfvyPmVMo        20.0      30.0\n2  --U7joUcTCo         0.0      10.0\n3  --i-y1v8Hy8         0.0       9.0\n4  -0BIyqJj9ZU        30.0      40.0", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>video_id</th>\n      <th>start_time</th>\n      <th>end_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>--4gqARaEJE</td>\n      <td>0.0</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>--BfvyPmVMo</td>\n      <td>20.0</td>\n      <td>30.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>--U7joUcTCo</td>\n      <td>0.0</td>\n      <td>10.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>--i-y1v8Hy8</td>\n      <td>0.0</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0BIyqJj9ZU</td>\n      <td>30.0</td>\n      <td>40.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "#Loading the evaluation data and labels to numpy objects\ndef load_data(hdf5_path):\n    \"\"\"\n    Loads the data into numpy objects. \n    Input : Path to data.\n    Output : Train/Test examples, corresponding labels, corresponding youtube video_id.\n    \"\"\"\n    with h5py.File(hdf5_path, 'r') as hf:\n        x = hf.get('x')\n        y = hf.get('y')\n        video_id_list = hf.get('video_id_list')\n        x = np.array(x)\n        y = list(y)\n        video_id_list = list(video_id_list)\n        \n    return x, y, video_id_list\n\ndef uint8_to_float32(x):\n    return (np.float32(x) - 128.) / 128.\n    \ndef bool_to_float32(y):\n    return np.float32(y)\n\n(x, y, video_id_list) = load_data('eval.h5')\nx = uint8_to_float32(x)\t\t# shape: (N, 10, 128)\ny = bool_to_float32(y)\t\t# shape: (N, 527)\n", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Building the Model\nIn the below cells we build the model and load the weights pre-trained on IBM cloud/dlaas."}, {"metadata": {}, "cell_type": "code", "source": "#Building the model\n\nimport keras\nfrom keras.models import Model\nfrom keras.layers import (Input, Dense, BatchNormalization, Dropout, Lambda,\n                          Activation, Concatenate)\nimport keras.backend as K\nfrom keras.optimizers import Adam\n\ntry:\n    import cPickle\nexcept BaseException:\n    import _pickle as cPickle\n\n\ndef average_pooling(inputs, **kwargs):\n    input = inputs[0]   # (batch_size, time_steps, freq_bins)\n    return K.mean(input, axis=1)\n\n\ndef max_pooling(inputs, **kwargs):\n    input = inputs[0]   # (batch_size, time_steps, freq_bins)\n    return K.max(input, axis=1)\n\n\ndef attention_pooling(inputs, **kwargs):\n    [out, att] = inputs\n\n    epsilon = 1e-7\n    att = K.clip(att, epsilon, 1. - epsilon)\n    normalized_att = att / K.sum(att, axis=1)[:, None, :]\n\n    return K.sum(out * normalized_att, axis=1)\n\n\ndef pooling_shape(input_shape):\n\n    if isinstance(input_shape, list):\n        (sample_num, time_steps, freq_bins) = input_shape[0]\n\n    else:\n        (sample_num, time_steps, freq_bins) = input_shape\n\n    return (sample_num, freq_bins)\n\nmodel_type = 'decision_level_multi_attention'\ntime_steps = 10\nfreq_bins = 128\nclasses_num = 527\n\n# Hyper parameters\nhidden_units = 1024\ndrop_rate = 0.5\nbatch_size = 500\n\n# Embedded layers\ninput_layer = Input(shape=(time_steps, freq_bins))\n\na1 = Dense(hidden_units)(input_layer)\na1 = BatchNormalization()(a1)\na1 = Activation('relu')(a1)\na1 = Dropout(drop_rate)(a1)\n\na2 = Dense(hidden_units)(a1)\na2 = BatchNormalization()(a2)\na2 = Activation('relu')(a2)\na2 = Dropout(drop_rate)(a2)\n\na3 = Dense(hidden_units)(a2)\na3 = BatchNormalization()(a3)\na3 = Activation('relu')(a3)\na3 = Dropout(drop_rate)(a3)\n\n# Pooling layers\nif model_type == 'decision_level_max_pooling':\n    '''Global max pooling.\n\n    [1] Choi, Keunwoo, et al. \"Automatic tagging using deep convolutional \n    neural networks.\" arXiv preprint arXiv:1606.00298 (2016).\n    '''\n    cla = Dense(classes_num, activation='sigmoid')(a3)\n    output_layer = Lambda(max_pooling, output_shape=pooling_shape)([cla])\n\nelif model_type == 'decision_level_average_pooling':\n    '''Global average pooling.\n\n    [2] Lin, Min, et al. Qiang Chen, and Shuicheng Yan. \"Network in \n    network.\" arXiv preprint arXiv:1312.4400 (2013).\n    '''\n    cla = Dense(classes_num, activation='sigmoid')(a3)\n    output_layer = Lambda(\n        average_pooling,\n        output_shape=pooling_shape)(\n        [cla])\n\nelif model_type == 'decision_level_single_attention':\n    '''Decision level single attention pooling.\n\n    [3] Kong, Qiuqiang, et al. \"Audio Set classification with attention\n    model: A probabilistic perspective.\" arXiv preprint arXiv:1711.00927\n    (2017).\n    '''\n    cla = Dense(classes_num, activation='sigmoid')(a3)\n    att = Dense(classes_num, activation='softmax')(a3)\n    output_layer = Lambda(\n        attention_pooling, output_shape=pooling_shape)([cla, att])\n\nelif model_type == 'decision_level_multi_attention':\n    '''Decision level multi attention pooling.\n\n    [4] Yu, Changsong, et al. \"Multi-level Attention Model for Weakly\n    Supervised Audio Classification.\" arXiv preprint arXiv:1803.02353\n    (2018).\n    '''\n    cla1 = Dense(classes_num, activation='sigmoid')(a2)\n    att1 = Dense(classes_num, activation='softmax')(a2)\n    out1 = Lambda(\n        attention_pooling, output_shape=pooling_shape)([cla1, att1])\n\n    cla2 = Dense(classes_num, activation='sigmoid')(a3)\n    att2 = Dense(classes_num, activation='softmax')(a3)\n    out2 = Lambda(\n        attention_pooling, output_shape=pooling_shape)([cla2, att2])\n\n    b1 = Concatenate(axis=-1)([out1, out2])\n    b1 = Dense(classes_num)(b1)\n    output_layer = Activation('sigmoid')(b1)\n\nelif model_type == 'feature_level_attention':\n    '''Feature level attention.\n\n    [1] To be appear.\n    '''\n    cla = Dense(hidden_units, activation='linear')(a3)\n    att = Dense(hidden_units, activation='sigmoid')(a3)\n    b1 = Lambda(\n        attention_pooling, output_shape=pooling_shape)([cla, att])\n\n    b1 = BatchNormalization()(b1)\n    b1 = Activation(activation='relu')(b1)\n    b1 = Dropout(drop_rate)(b1)\n\n    output_layer = Dense(classes_num, activation='sigmoid')(b1)\n\nelse:\n    raise Exception(\"Incorrect model_type!\")\n\n# Build model\nmodel = Model(inputs=input_layer, outputs=output_layer)\nmodel.summary()\n", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "WARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 10, 128)      0                                            \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 10, 1024)     132096      input_1[0][0]                    \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 10, 1024)     4096        dense_1[0][0]                    \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 10, 1024)     0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 10, 1024)     0           activation_1[0][0]               \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 10, 1024)     1049600     dropout_1[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 10, 1024)     4096        dense_2[0][0]                    \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 10, 1024)     0           batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\ndropout_2 (Dropout)             (None, 10, 1024)     0           activation_2[0][0]               \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 10, 1024)     1049600     dropout_2[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 10, 1024)     4096        dense_3[0][0]                    \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 10, 1024)     0           batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\ndropout_3 (Dropout)             (None, 10, 1024)     0           activation_3[0][0]               \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 10, 527)      540175      dropout_2[0][0]                  \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, 10, 527)      540175      dropout_2[0][0]                  \n__________________________________________________________________________________________________\ndense_6 (Dense)                 (None, 10, 527)      540175      dropout_3[0][0]                  \n__________________________________________________________________________________________________\ndense_7 (Dense)                 (None, 10, 527)      540175      dropout_3[0][0]                  \n__________________________________________________________________________________________________\nlambda_1 (Lambda)               (None, 527)          0           dense_4[0][0]                    \n                                                                 dense_5[0][0]                    \n__________________________________________________________________________________________________\nlambda_2 (Lambda)               (None, 527)          0           dense_6[0][0]                    \n                                                                 dense_7[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 1054)         0           lambda_1[0][0]                   \n                                                                 lambda_2[0][0]                   \n__________________________________________________________________________________________________\ndense_8 (Dense)                 (None, 527)          555985      concatenate_1[0][0]              \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 527)          0           dense_8[0][0]                    \n==================================================================================================\nTotal params: 4,960,269\nTrainable params: 4,954,125\nNon-trainable params: 6,144\n__________________________________________________________________________________________________\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#Loading weights\nmodel.load_weights(\"final_weights.h5\")", "execution_count": 10, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Demo supporting code \nThis is the supporting code to run the demo at the end of this notebook."}, {"metadata": {}, "cell_type": "code", "source": "def demo(v):\n    \"\"\"\n    A function to demonstrate the audio classification.\n    Input : a random number to retrieve a query video.\n    Output : video embed string for the YouTube video.\n    Prints : Top 5 class probabilities from the classifier.\n    \"\"\"\n    test_data = x[v:v+1,:,:]\n    current_infer = model.predict(test_data)\n    current_video = str(video_id_list[v],'utf-8')\n    print(current_video)\n    start_time = int(df_data_2.loc[df_data_2['video_id'] == current_video]['start_time'])\n    video_string = '<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/'+current_video+'?autoplay=1&start='+str(start_time)+';autoplay=1 frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>'\n    print('Predicted Labels :\\n')\n    print(df_data_1.loc[current_infer[0].argsort()[-5:][::-1]]['display_name'])\n    #print('Ground Truth Labels :\\n')\n    #print(df_data_1.loc[y[v].argsort()[-5:][::-1]]['display_name'])\n    print(\"Playing video snippet below.. Turn on the speakers..\\n\")\n    return video_string", "execution_count": 11, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Real Time Demo\n\nReplace the number below to change the video and generate a real-time inference."}, {"metadata": {}, "cell_type": "code", "source": "#Try out a random number between 0 and 20000 \nvideo_number = 800\nHTML(demo(video_number))", "execution_count": 12, "outputs": [{"output_type": "stream", "text": "10YXuv9Go0E\nPredicted Labels :\n\n342                   Skateboard\n137                        Music\n0                         Speech\n509    Outside, urban or manmade\n468                Whack, thwack\nName: display_name, dtype: object\nPlaying video snippet below.. Turn on the speakers..\n\n", "name": "stdout"}, {"output_type": "stream", "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/IPython/core/display.py:689: UserWarning: Consider using IPython.display.IFrame instead\n  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n", "name": "stderr"}, {"output_type": "execute_result", "execution_count": 12, "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/10YXuv9Go0E?autoplay=1&start=140;autoplay=1 frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "# Reverse Search Audio using keywords\n\nIn this section we will first perform inference on the full test dataset and store it to later retrieve search results."}, {"metadata": {}, "cell_type": "code", "source": "#First we get the inference for all our data and store it under `inferences`\ninferences = model.predict(x, batch_size=100)\n#If you are facing memory/time issues, try running for a smaller subset\n#inferences = model.predict(x[0:1000])", "execution_count": 13, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Now we write a function to retrieve the required audios\ndef search_audio(keyword, infer=inferences):\n    \"\"\"\n    Uses the inferences made using the audioset classifier to lookup and retrieve relevant audio/video for a given keyword.\n    Inputs : search query, inferences on test dataset.\n    Outputs : YouTube embed link for the strongest video returned and a list of all videos containing the search query.\n    \"\"\"\n    try:\n        class_id = int(df_data_1.loc[df_data_1['display_name'] == keyword]['index'])\n        print(\"Retrieving videos containing \"+keyword +\" with the highest probabilities...\")\n    except:\n        class_id = -1\n        print(\"Search Query is invalid!\")\n    strong_inferences = np.argsort(inferences,axis = 1)[:,-5:]\n    video_ids = np.where(strong_inferences==class_id)[0]\n    video_strings = []\n    max_prob = -1\n    strongest_video_embed = ''\n    print_counter = 0\n    if(video_ids.any()):\n        print(\"...Done!\")\n        print(\"Printing a few strong results.. \")\n    for v in video_ids:\n        current_video = str(video_id_list[v],'utf-8')\n        start_time = df_data_2.loc[df_data_2['video_id'] == current_video]['start_time'].astype(int)\n        video_string = 'https://www.youtube.com/watch?v='+current_video+'&t='+str(start_time)\n        if(inferences[v][class_id]>0.8 and print_counter<10):\n            print(video_string + \" contains \"+keyword+\" with probability \"+ str(inferences[v][class_id]))\n            print_counter +=1\n        video_strings.append(video_string)\n        if inferences[v][class_id]>max_prob:\n            max_prob = inferences[v][class_id]\n            max_video = current_video\n            max_time = start_time\n    if(not video_strings):\n        print(\"No videos found for the search query: \"+keyword )\n    else:\n        strongest_video_embed = '<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/'+max_video+'?autoplay=1&start='+str(max_time)+';autoplay=1 frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>'\n    return strongest_video_embed,video_strings", "execution_count": 14, "outputs": []}, {"metadata": {"scrolled": false}, "cell_type": "code", "source": "search_query = 'Rain'\nembed = search_audio(search_query)[0]\nif(embed):\n    print(\"\\n Playing video with the strongest probability of containing \"+search_query+\" ..\")\nHTML(embed)", "execution_count": 15, "outputs": [{"output_type": "stream", "text": "Retrieving videos containing Rain with the highest probabilities...\n...Done!\nPrinting a few strong results.. \nhttps://www.youtube.com/watch?v=-3-4qmWSJXU&t=34    30\nName: start_time, dtype: int64 contains Rain with probability 0.9672336\nhttps://www.youtube.com/watch?v=0BauNGmZtTU&t=477    250\nName: start_time, dtype: int64 contains Rain with probability 0.99831176\nhttps://www.youtube.com/watch?v=10rH37YYvKU&t=806    30\nName: start_time, dtype: int64 contains Rain with probability 0.9436661\nhttps://www.youtube.com/watch?v=1B-RuZgSqf8&t=862    30\nName: start_time, dtype: int64 contains Rain with probability 0.90838933\nhttps://www.youtube.com/watch?v=1De-OI8YG-M&t=877    7\nName: start_time, dtype: int64 contains Rain with probability 0.94205034\n\n Playing video with the strongest probability of containing Rain ..\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 15, "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/0BauNGmZtTU?autoplay=1&start=477    250\nName: start_time, dtype: int64;autoplay=1 frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>"}, "metadata": {}}]}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}